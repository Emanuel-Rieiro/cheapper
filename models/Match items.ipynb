{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b570f36",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c05716ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6bfd31",
   "metadata": {},
   "source": [
    "### Data download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1e96260",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client(\"s3\")\n",
    "s3.download_file(\n",
    "    Bucket=\"cheapper\", Key=\"webscraping_results_17-01-2023.csv\", Filename=\"data.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f12ad1",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0683fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv').drop('Unnamed: 0',axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07fa8db",
   "metadata": {},
   "source": [
    "### What we want to do?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab7ca26",
   "metadata": {},
   "source": [
    "These items are all the same, but have slightly different name depending of the source where we got them from.\n",
    "\n",
    "The idea would be to create a model that matches products we belive are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6908c13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                                                 17-01-2023\n",
       "ecomm_name                                             eldorado\n",
       "name                                        YERBA CANARIAS 1KG \n",
       "src           https://eldoradouy.vtexassets.com/arquivos/ids...\n",
       "price_1                                                  188,00\n",
       "price_2                                                     NaN\n",
       "Name: 261, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[261]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a14ea4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                                                 17-01-2023\n",
       "ecomm_name                                               elclon\n",
       "name                                        YERBA CANARIAS 1 KG\n",
       "src           https://f.fcdn.app/imgs/95fec6/www.elclon.com....\n",
       "price_1                                                     185\n",
       "price_2                                                     NaN\n",
       "Name: 69, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[69]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b261a93a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                                                 17-01-2023\n",
       "ecomm_name                                               devoto\n",
       "name                                        Yerba CANARIAS 1 kg\n",
       "src           https://geant.vteximg.com.br/arquivos/ids/2921...\n",
       "price_1                                                     188\n",
       "price_2                                                     NaN\n",
       "Name: 423, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[423]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13f3e19",
   "metadata": {},
   "source": [
    "### Unsupervised clasification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "343f73ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\emanu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f543e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def containsNumber(value):\n",
    "    for character in value:\n",
    "        if character.isdigit():\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79426390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(texts):\n",
    "    stop_words = set(stopwords.words('spanish'))\n",
    "    stop_words.add('gr')\n",
    "    stop_words.add('g')\n",
    "    stop_words.add('grs.')\n",
    "    stop_words.add('grs')\n",
    "    stop_words.add('kg')\n",
    "    stop_words.add('kg.')\n",
    "    cleaned_texts = []\n",
    "    for text in texts:\n",
    "        cleaned_text = [word for word in text.split() if word.lower() not in stop_words]\n",
    "        cleaned_texts.append(' '.join(cleaned_text))\n",
    "    return cleaned_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57ac2f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords_together(texts):\n",
    "    \n",
    "    new_names = []\n",
    "    for names in texts:\n",
    "        \n",
    "        new_name = []\n",
    "        for name in names.split():\n",
    "            \n",
    "            if containsNumber(name):\n",
    "                new_name.append(re.findall(r'\\d+', name)[0])\n",
    "            else:\n",
    "                new_name.append(name)\n",
    "        \n",
    "        new_names.append(' '.join(new_name))\n",
    "    return new_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d82f39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abac7553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bow(texts):\n",
    "    vectorizer = CountVectorizer()\n",
    "    bow = vectorizer.fit_transform(texts)\n",
    "    return bow, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24ffa863",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['name'] = df['name'].astype(str) # get everything to str\n",
    "df['name'] = df['name'].str.lower() # lowercase everything\n",
    "df['name'] = df['name'].str.replace('c/','') # get rid of the c/\n",
    "\n",
    "df['name'] = remove_stopwords(df['name'].values) # stopwords\n",
    "df['name'] = remove_stopwords_together(df['name']) # clean \"500g\" like descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aada150b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 1: Lo puedo seguir explorando mañana en clase\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv =  CountVectorizer(tokenizer=lambda txt: txt.split()) # tengo que usar una función custom\n",
    "bow = cv.fit_transform(df['name'])\n",
    "\n",
    "count_array = bow.toarray()\n",
    "df_features = pd.DataFrame(data=count_array, columns = cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0449dc36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yerba canarias 1'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['name'].loc[423]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "caac98c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1           1\n",
       "canarias    1\n",
       "yerba       1\n",
       "Name: 423, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.loc[:,df_features.loc[423] == 1].loc[423]"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "cheapper2",
   "language": "python",
   "name": "cheapper2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
